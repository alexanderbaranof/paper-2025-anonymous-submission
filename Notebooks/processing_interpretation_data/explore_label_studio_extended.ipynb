{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\n",
    "    \"/home/alex/paper-2025-anonymous-submission/Data/raw_data/label_studio_interpretation_extended.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_annot(annot):\n",
    "    all_result = dict()\n",
    "    for ann in annot:\n",
    "        for r in ann[\"result\"]:\n",
    "            all_result[r[\"from_name\"]] = r[\"value\"][\"choices\"][0]\n",
    "\n",
    "    return all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>annotations</th>\n",
       "      <th>file_upload</th>\n",
       "      <th>drafts</th>\n",
       "      <th>predictions</th>\n",
       "      <th>data</th>\n",
       "      <th>meta</th>\n",
       "      <th>created_at</th>\n",
       "      <th>updated_at</th>\n",
       "      <th>inner_id</th>\n",
       "      <th>total_annotations</th>\n",
       "      <th>cancelled_annotations</th>\n",
       "      <th>total_predictions</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>unresolved_comment_count</th>\n",
       "      <th>last_comment_updated_at</th>\n",
       "      <th>project</th>\n",
       "      <th>updated_by</th>\n",
       "      <th>comment_authors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5119</td>\n",
       "      <td>[{'id': 1426, 'completed_by': 1, 'result': [{'...</td>\n",
       "      <td>30b9bb25-razmetka_extended.csv</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'headline': 'Налетай, позеленело', 'lead': 'К...</td>\n",
       "      <td>{}</td>\n",
       "      <td>2025-01-31 20:28:28.862004+00:00</td>\n",
       "      <td>2025-02-01 11:56:19.167703+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaT</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                        annotations  \\\n",
       "0  5119  [{'id': 1426, 'completed_by': 1, 'result': [{'...   \n",
       "\n",
       "                      file_upload drafts predictions  \\\n",
       "0  30b9bb25-razmetka_extended.csv     []          []   \n",
       "\n",
       "                                                data meta  \\\n",
       "0  {'headline': 'Налетай, позеленело', 'lead': 'К...   {}   \n",
       "\n",
       "                        created_at                       updated_at  inner_id  \\\n",
       "0 2025-01-31 20:28:28.862004+00:00 2025-02-01 11:56:19.167703+00:00         1   \n",
       "\n",
       "   total_annotations  cancelled_annotations  total_predictions  comment_count  \\\n",
       "0                  1                      0                  0              0   \n",
       "\n",
       "   unresolved_comment_count last_comment_updated_at  project  updated_by  \\\n",
       "0                         0                     NaT        9           1   \n",
       "\n",
       "  comment_authors  \n",
       "0              []  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"annot_parsed\"] = df[\"annotations\"].apply(extract_annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.DataFrame(df[\"annot_parsed\"].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, dff], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'annotations', 'file_upload', 'drafts', 'predictions', 'data',\n",
       "       'meta', 'created_at', 'updated_at', 'inner_id', 'total_annotations',\n",
       "       'cancelled_annotations', 'total_predictions', 'comment_count',\n",
       "       'unresolved_comment_count', 'last_comment_updated_at', 'project',\n",
       "       'updated_by', 'comment_authors', 'annot_parsed', 'gpt4o_eval',\n",
       "       'gigachat_lite_eval', 'gigachat_max_eval', 'mistral_nemo_eval',\n",
       "       'yagpt_eval'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gpt4o_eval\"] = df[\"gpt4o_eval\"].apply(lambda x: 1 if x == \"Good\" else 0)\n",
    "df[\"gigachat_lite_eval\"] = df[\"gigachat_lite_eval\"].apply(lambda x: 1 if x == \"Good\" else 0)\n",
    "df[\"gigachat_max_eval\"] = df[\"gigachat_max_eval\"].apply(lambda x: 1 if x == \"Good\" else 0)\n",
    "df[\"mistral_nemo_eval\"] = df[\"mistral_nemo_eval\"].apply(lambda x: 1 if x == \"Good\" else 0)\n",
    "df[\"yagpt_eval\"] = df[\"yagpt_eval\"].apply(lambda x: 1 if x == \"Good\" else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_preds = [\n",
    "    \"gigachat_lite_eval\",\n",
    "    \"gigachat_max_eval\",\n",
    "    \"yagpt_eval\",\n",
    "    \"mistral_nemo_eval\",\n",
    "    \"gpt4o_eval\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gigachat_lite_eval    0.11\n",
       "gigachat_max_eval     0.28\n",
       "yagpt_eval            0.20\n",
       "mistral_nemo_eval     0.24\n",
       "gpt4o_eval            0.48\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(df[cols_preds].sum() / len(df), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"/home/alex/paper-2025-anonymous-submission/Data/processed_data/manual_interpretation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
